#!/usr/bin/env python3
"""
Korean RAG Orchestrator Service - í•œêµ­ì–´ ìµœì í™” RAG ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
PyTorch/Transformers ì—†ì´ TF-IDF + Kiwië¥¼ í™œìš©í•œ í•œêµ­ì–´ íŠ¹í™” ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
"""

import sys
import os
import asyncio
import logging
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path

# FastAPI ë° ê¸°ë³¸ ì˜ì¡´ì„±
from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn
import aiohttp
import httpx

# í•œêµ­ì–´ ì²˜ë¦¬ ë° ë²¡í„°í™” (ê¸°ì¡´ backend ëª¨ë“ˆ í™œìš©)
sys.path.append('/home/ptyoung/work/sdc_i/backend')
from services.korean_embeddings import KoreanEmbeddingService, KoreanTextProcessor

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# FastAPI ì•± ì„¤ì •
app = FastAPI(
    title="Korean RAG Orchestrator",
    description="í•œêµ­ì–´ íŠ¹í™” RAG íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (TF-IDF + Kiwi)",
    version="2.0.0-korean-optimized"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ”„ LOCAL LLM MIGRATION POINT 6: ì„œë¹„ìŠ¤ URL ì„¤ì •
# í˜„ì¬: Gemini ê¸°ë°˜ Korean RAG Service URL
# í–¥í›„: ë¡œì»¬ LLM ì„œë¹„ìŠ¤ URLë¡œ ë³€ê²½ ë˜ëŠ” ì¶”ê°€
#
# ë¡œì»¬ LLM ì„œë¹„ìŠ¤ URL ì˜ˆì‹œ:
# OLLAMA_SERVICE_URL = "http://localhost:11434"      # Ollama ê¸°ë³¸ í¬íŠ¸
# VLLM_SERVICE_URL = "http://localhost:8000"         # vLLM ì¶”ë¡  ì„œë²„
# TRANSFORMERS_SERVICE_URL = "http://localhost:8001" # Transformers ì„œë¹„ìŠ¤
# LOCAL_LLM_SERVICE_URL = "http://localhost:8009"    # í†µí•© ë¡œì»¬ LLM ì„œë¹„ìŠ¤ (ê¸°ì¡´ í¬íŠ¸ ì¬ì‚¬ìš©)
#
# í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥:
# KOREAN_RAG_SERVICE_URL = os.getenv("KOREAN_RAG_SERVICE_URL", "http://localhost:8009")
# LLM_SERVICE_TYPE = os.getenv("LLM_SERVICE_TYPE", "gemini")  # gemini, ollama, vllm, transformers

# ì„œë¹„ìŠ¤ URL ì„¤ì •
MAIN_BACKEND_URL = "http://localhost:8000"
MILVUS_SERVICE_URL = "http://localhost:8010"
KOREAN_RAG_SERVICE_URL = "http://localhost:8009"  # í–¥í›„ LOCAL_LLM_SERVICE_URLë¡œ ë³€ê²½

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
korean_embedding_service = None
korean_text_processor = None

# Pydantic ëª¨ë¸
class DocumentUploadRequest(BaseModel):
    user_id: str
    filename: str
    content: str
    metadata: Dict[str, Any] = Field(default_factory=dict)

class DocumentChunk(BaseModel):
    chunk_id: str
    content: str
    vector: List[float]
    metadata: Dict[str, Any]
    korean_features: Dict[str, Any]

class RAGQueryRequest(BaseModel):
    query: str
    user_id: str
    max_chunks: int = 5
    similarity_threshold: float = 0.3

class RAGResponse(BaseModel):
    query: str
    response: str
    sources: List[Dict[str, Any]]
    korean_analysis: Dict[str, Any]
    processing_time: float

# ì„œë¹„ìŠ¤ ìƒíƒœ ê´€ë¦¬
class ServiceStatus:
    def __init__(self):
        self.korean_embedding_ready = False
        self.milvus_connected = False
        self.korean_rag_ready = False
        
    async def check_services(self):
        """ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            # Korean embedding service í™•ì¸ (ë¡œì»¬)
            global korean_embedding_service, korean_text_processor
            if korean_embedding_service is None:
                korean_embedding_service = KoreanEmbeddingService(embedding_dim=768)
                korean_text_processor = KoreanTextProcessor()
                logger.info("âœ… Korean Embedding Service ë¡œì»¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ")
            self.korean_embedding_ready = True
            
            # Milvus ì„œë¹„ìŠ¤ í™•ì¸
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(f"{MILVUS_SERVICE_URL}/health", timeout=5.0)
                    self.milvus_connected = response.status_code == 200
            except:
                self.milvus_connected = False
                logger.warning("âš ï¸ Milvus ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
            
            # Korean RAG ì„œë¹„ìŠ¤ í™•ì¸
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(f"{KOREAN_RAG_SERVICE_URL}/health", timeout=5.0)
                    self.korean_rag_ready = response.status_code == 200
            except:
                self.korean_rag_ready = False
                logger.warning("âš ï¸ Korean RAG ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

service_status = ServiceStatus()

@app.on_event("startup")
async def startup_event():
    """ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    logger.info("ğŸš€ Korean RAG Orchestrator ì‹œì‘ ì¤‘...")
    await service_status.check_services()
    logger.info("ğŸ“ Korean RAG Orchestrator ì¤€ë¹„ ì™„ë£Œ (Port 8008)")

@app.get("/")
async def root():
    return {
        "service": "Korean RAG Orchestrator",
        "version": "2.0.0-korean-optimized",
        "status": "running",
        "features": [
            "TF-IDF ê¸°ë°˜ í•œêµ­ì–´ ì„ë² ë”©",
            "Kiwi í˜•íƒœì†Œ ë¶„ì„",
            "Milvus ë²¡í„° ì €ì¥",
            "í•œêµ­ì–´ ìµœì í™” ì²­í‚¹"
        ]
    }

@app.get("/health")
async def health_check():
    await service_status.check_services()
    return {
        "status": "healthy",
        "services": {
            "korean_embedding": service_status.korean_embedding_ready,
            "milvus": service_status.milvus_connected,
            "korean_rag": service_status.korean_rag_ready
        },
        "timestamp": datetime.now().isoformat()
    }

@app.post("/process_document")
async def process_document(request: DocumentUploadRequest):
    """ë¬¸ì„œë¥¼ í•œêµ­ì–´ ìµœì í™” ì²˜ë¦¬í•˜ì—¬ ë²¡í„°í™” ë° ì €ì¥"""
    try:
        start_time = datetime.now()
        
        # 1. í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        processed_text = korean_text_processor.preprocess_text(request.content)
        
        # 2. í•œêµ­ì–´ ì²­í‚¹ (ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• )
        chunks = korean_text_processor.chunk_text(processed_text, chunk_size=500, overlap=50)
        
        # 3. ê° ì²­í¬ë¥¼ TF-IDF ë²¡í„°ë¡œ ë³€í™˜
        processed_chunks = []
        for i, chunk_text in enumerate(chunks):
            # ì²­í¬ ë²¡í„°í™”
            try:
                vector = korean_embedding_service.embed_text(chunk_text)
                
                # í•œêµ­ì–´ íŠ¹ì„± ë¶„ì„
                korean_features = {
                    "tokenized": korean_text_processor.tokenize(chunk_text),
                    "keywords": korean_text_processor.extract_keywords(chunk_text),
                    "char_count": len(chunk_text),
                    "token_count": len(korean_text_processor.tokenize(chunk_text))
                }
                
                chunk_obj = DocumentChunk(
                    chunk_id=f"{request.user_id}_{uuid.uuid4().hex[:8]}_{i}",
                    content=chunk_text,
                    vector=vector.tolist(),
                    metadata={
                        "user_id": request.user_id,
                        "filename": request.filename,
                        "chunk_index": i,
                        "total_chunks": len(chunks),
                        "processed_at": datetime.now().isoformat(),
                        **request.metadata
                    },
                    korean_features=korean_features
                )
                processed_chunks.append(chunk_obj)
                
            except Exception as e:
                logger.error(f"ì²­í¬ {i} ë²¡í„°í™” ì‹¤íŒ¨: {e}")
                continue
        
        # 4. Milvusì— ë²¡í„° ì €ì¥ (ì„œë¹„ìŠ¤ ì—°ê²° ì‹œ)
        stored_count = 0
        if service_status.milvus_connected:
            try:
                async with httpx.AsyncClient() as client:
                    for chunk in processed_chunks:
                        store_data = {
                            "chunk_id": chunk.chunk_id,
                            "vector": chunk.vector,
                            "content": chunk.content,
                            "metadata": chunk.metadata,
                            "korean_features": chunk.korean_features
                        }
                        response = await client.post(
                            f"{MILVUS_SERVICE_URL}/store",
                            json=store_data,
                            timeout=10.0
                        )
                        if response.status_code == 200:
                            stored_count += 1
            except Exception as e:
                logger.error(f"Milvus ì €ì¥ ì‹¤íŒ¨: {e}")
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return {
            "status": "success",
            "document_id": f"{request.user_id}_{uuid.uuid4().hex[:8]}",
            "chunks_processed": len(processed_chunks),
            "chunks_stored": stored_count,
            "korean_features": {
                "total_tokens": sum(len(chunk.korean_features.get("tokenized", [])) for chunk in processed_chunks),
                "total_keywords": sum(len(chunk.korean_features.get("keywords", [])) for chunk in processed_chunks),
                "average_chunk_size": sum(chunk.korean_features.get("char_count", 0) for chunk in processed_chunks) / len(processed_chunks) if processed_chunks else 0
            },
            "processing_time": processing_time,
            "services_used": {
                "korean_embedding": True,
                "milvus_storage": service_status.milvus_connected
            }
        }
        
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/query")
async def rag_query(request: RAGQueryRequest):
    """í•œêµ­ì–´ ìµœì í™” RAG ì§ˆì˜ ì²˜ë¦¬"""
    try:
        start_time = datetime.now()
        
        # 1. ì§ˆì˜ í•œêµ­ì–´ ì „ì²˜ë¦¬ ë° ë²¡í„°í™”
        query_processed = korean_text_processor.preprocess_text(request.query)
        query_vector = korean_embedding_service.embed_text(query_processed)
        
        # 2. ì§ˆì˜ ë¶„ì„
        korean_analysis = {
            "original_query": request.query,
            "processed_query": query_processed,
            "tokenized": korean_text_processor.tokenize(query_processed),
            "keywords": korean_text_processor.extract_keywords(query_processed)
        }
        
        # 3. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (Milvus ì—°ê²° ì‹œ)
        retrieved_chunks = []
        if service_status.milvus_connected:
            try:
                async with httpx.AsyncClient() as client:
                    search_data = {
                        "vector": query_vector.tolist(),
                        "top_k": request.max_chunks,
                        "threshold": request.similarity_threshold
                    }
                    response = await client.post(
                        f"{MILVUS_SERVICE_URL}/search",
                        json=search_data,
                        timeout=15.0
                    )
                    if response.status_code == 200:
                        retrieved_chunks = response.json().get("results", [])
            except Exception as e:
                logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # 4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë° ì‘ë‹µ ìƒì„±
        context_text = "\n\n".join([chunk.get("content", "") for chunk in retrieved_chunks])
        
        # ğŸ”„ LOCAL LLM MIGRATION POINT 5: LLM ì‘ë‹µ ìƒì„± í˜¸ì¶œë¶€
        # í˜„ì¬: Korean RAG Gemini Service (Port 8009) HTTP í˜¸ì¶œ
        # í–¥í›„: ë¡œì»¬ LLM ì„œë¹„ìŠ¤ í˜¸ì¶œ ë˜ëŠ” ì§ì ‘ ì¶”ë¡ ìœ¼ë¡œ ë³€ê²½
        #
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜µì…˜ë“¤:
        # 
        # ì˜µì…˜ 1: ë¡œì»¬ LLM ì„œë¹„ìŠ¤ HTTP í˜¸ì¶œ (í˜„ì¬ êµ¬ì¡° ìœ ì§€)
        # OLLAMA_SERVICE_URL = "http://localhost:11434"
        # VLLM_SERVICE_URL = "http://localhost:8000" 
        # LOCAL_LLM_SERVICE_URL = "http://localhost:8009"  # ë™ì¼ í¬íŠ¸ ì¬ì‚¬ìš©
        #
        # ì˜µì…˜ 2: ì§ì ‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ (ì„±ëŠ¥ ìµœì í™”)
        # from services.local_llm_service import LocalLLMService
        # local_llm = LocalLLMService(model_type="ollama")
        # response_text = await local_llm.generate_response(llm_data)
        #
        # ì˜µì…˜ 3: ë©€í‹° LLM ë¡œë“œë°¸ëŸ°ì‹±
        # available_models = ["gemma-7b-ko", "qwen-14b-chat", "deepseek-33b"]
        # best_model = select_best_model_for_query(request.query, available_models)
        # response_text = await generate_with_model(best_model, llm_data)
        
        # 5. LLM ì‘ë‹µ ìƒì„± (Korean RAG ì„œë¹„ìŠ¤ ì—°ê²° ì‹œ)
        response_text = "ë¬¸ì„œ ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆì§€ë§Œ ì‘ë‹µ ìƒì„± ì„œë¹„ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        if service_status.korean_rag_ready:
            try:
                async with httpx.AsyncClient() as client:
                    llm_data = {
                        "query": request.query,
                        "context": context_text,
                        "korean_analysis": korean_analysis
                    }
                    # í˜„ì¬: Gemini ì„œë¹„ìŠ¤ í˜¸ì¶œ (í–¥í›„ ë¡œì»¬ LLM ì„œë¹„ìŠ¤ë¡œ URL ë³€ê²½)
                    response = await client.post(
                        f"{KOREAN_RAG_SERVICE_URL}/generate",  # í–¥í›„: LOCAL_LLM_SERVICE_URL
                        json=llm_data,
                        timeout=30.0  # ë¡œì»¬ LLMì€ ë” ì§§ì€ íƒ€ì„ì•„ì›ƒ ê°€ëŠ¥ (5-10ì´ˆ)
                    )
                    if response.status_code == 200:
                        response_text = response.json().get("response", response_text)
            except Exception as e:
                logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
                response_text = f"ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ: {context_text[:500]}..." if context_text else "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return RAGResponse(
            query=request.query,
            response=response_text,
            sources=[{
                "chunk_id": chunk.get("chunk_id"),
                "content": chunk.get("content", "")[:200] + "...",
                "similarity": chunk.get("similarity", 0.0),
                "metadata": chunk.get("metadata", {})
            } for chunk in retrieved_chunks],
            korean_analysis=korean_analysis,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"RAG ì§ˆì˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/stats")
async def get_stats():
    """ì„œë¹„ìŠ¤ í†µê³„ ì •ë³´"""
    await service_status.check_services()
    return {
        "service": "Korean RAG Orchestrator",
        "status": {
            "korean_embedding": service_status.korean_embedding_ready,
            "milvus": service_status.milvus_connected,
            "korean_rag": service_status.korean_rag_ready
        },
        "features": {
            "korean_tokenization": KIWI_AVAILABLE if 'KIWI_AVAILABLE' in globals() else False,
            "tfidf_vectorization": True,
            "korean_preprocessing": True,
            "milvus_storage": service_status.milvus_connected
        },
        "version": "2.0.0-korean-optimized"
    }

@app.get("/documents")
async def get_all_documents():
    """ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ"""
    try:
        if service_status.milvus_connected:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{MILVUS_SERVICE_URL}/stats", timeout=5.0)
                if response.status_code == 200:
                    stats = response.json()
                    return {
                        "documents": [],
                        "total_vectors": stats.get("milvus", {}).get("total_vectors", 0),
                        "status": "connected"
                    }
        return {"documents": [], "total_vectors": 0, "status": "disconnected"}
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"documents": [], "total_vectors": 0, "status": "error"}

@app.get("/documents/{user_id}")
async def get_user_documents(user_id: str):
    """ì‚¬ìš©ìë³„ ë¬¸ì„œ ì¡°íšŒ"""
    try:
        # Korean RAG Serviceì—ì„œ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹œë„
        if service_status.korean_rag_connected:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{KOREAN_RAG_SERVICE_URL}/documents/{user_id}", timeout=5.0)
                if response.status_code == 200:
                    return response.json()
        
        # í´ë°±: ë¹ˆ ë¬¸ì„œ ëª©ë¡ ë°˜í™˜
        return {"documents": [], "user_id": user_id, "total": 0}
    except Exception as e:
        logger.error(f"ì‚¬ìš©ì ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"documents": [], "user_id": user_id, "total": 0}

@app.get("/documents/{document_id}")
async def get_document_details(document_id: str):
    """ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        if service_status.korean_rag_connected:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{KOREAN_RAG_SERVICE_URL}/documents/{document_id}", timeout=5.0)
                if response.status_code == 200:
                    return response.json()
        
        return {"document_id": document_id, "status": "not_found"}
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"document_id": document_id, "status": "error"}

@app.get("/documents/{document_id}/chunks")
async def get_document_chunks(document_id: str):
    """ë¬¸ì„œ ì²­í¬ ì¡°íšŒ"""
    try:
        if service_status.korean_rag_connected:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{KOREAN_RAG_SERVICE_URL}/documents/{document_id}/chunks", timeout=5.0)
                if response.status_code == 200:
                    return response.json()
        
        return {"chunks": [], "document_id": document_id, "total": 0}
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì²­í¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"chunks": [], "document_id": document_id, "total": 0}

if __name__ == "__main__":
    print("ğŸš€ Korean RAG Orchestrator ì‹œì‘ ì¤‘...")
    print("ğŸ“ í•œêµ­ì–´ íŠ¹í™” TF-IDF + Kiwi ê¸°ë°˜ RAG íŒŒì´í”„ë¼ì¸")
    print("ğŸ”— Running on http://0.0.0.0:8008")
    print("âœ… PyTorch/Transformers ì˜ì¡´ì„± ì—†ìŒ")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8008,
        log_level="info"
    )